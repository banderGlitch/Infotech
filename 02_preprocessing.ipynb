{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Target Creation - Failure in 24 Hours\n",
    "\n",
    "**Goal:** Create the target variable `failure_in_24h` = 1 if machine fails within the next 24 records (simulating 24 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "HORIZON = 24  # Records ahead = \"24 hours\" (configurable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('archive/ai4i2020.csv')\n",
    "df = df.sort_values('UDI').reset_index(drop=True)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target: failure_in_24h\n",
    "\n",
    "For each row i: target = 1 if ANY failure in rows i+1 to i+HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_failure_in_horizon(df: pd.DataFrame, horizon: int = 24) -> pd.Series:\n",
    "    \"\"\"Create target: 1 if failure occurs in next 'horizon' rows.\"\"\"\n",
    "    n = len(df)\n",
    "    target = np.zeros(n, dtype=int)\n",
    "    failures = df['Machine failure'].values\n",
    "    \n",
    "    for i in range(n - horizon):\n",
    "        if np.any(failures[i + 1 : i + 1 + horizon]):\n",
    "            target[i] = 1\n",
    "    \n",
    "    return pd.Series(target, index=df.index)\n",
    "\n",
    "df['failure_in_24h'] = create_failure_in_horizon(df, HORIZON)\n",
    "print(\"Target distribution:\")\n",
    "print(df['failure_in_24h'].value_counts())\n",
    "print(f\"\\nPositive rate: {df['failure_in_24h'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop last HORIZON rows (no future data to predict)\n",
    "df_trimmed = df.iloc[:-HORIZON].copy()\n",
    "print(f\"Rows after trimming: {len(df_trimmed)}\")\n",
    "print(df_trimmed['failure_in_24h'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived features (from domain knowledge)\n",
    "df_trimmed['Power_W'] = df_trimmed['Torque [Nm]'] * df_trimmed['Rotational speed [rpm]'] * (2 * np.pi / 60)\n",
    "df_trimmed['Temp_diff_K'] = df_trimmed['Process temperature [K]'] - df_trimmed['Air temperature [K]']\n",
    "df_trimmed['Overstrain_proxy'] = df_trimmed['Tool wear [min]'] * df_trimmed['Torque [Nm]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Type (L, M, H)\n",
    "df_trimmed['Type_encoded'] = df_trimmed['Type'].map({'L': 0, 'M': 1, 'H': 2})\n",
    "df_trimmed[['Type', 'Type_encoded']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns for modeling\n",
    "feature_cols = [\n",
    "    'Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]',\n",
    "    'Torque [Nm]', 'Tool wear [min]',\n",
    "    'Power_W', 'Temp_diff_K', 'Overstrain_proxy', 'Type_encoded'\n",
    "]\n",
    "target_col = 'failure_in_24h'\n",
    "\n",
    "X = df_trimmed[feature_cols]\n",
    "y = df_trimmed[target_col]\n",
    "\n",
    "print(\"Features:\", feature_cols)\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split (Time-Based)\n",
    "\n",
    "Use first 80% for train, last 20% for test - no shuffling (preserve temporal order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(df_trimmed) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples, {y_train.sum()} positives ({y_train.mean()*100:.2f}%)\")\n",
    "print(f\"Test:  {len(X_test)} samples, {y_test.sum()} positives ({y_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for modeling notebook\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "df_trimmed.to_csv('data/processed_data.csv', index=False)\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "X_test.to_csv('data/X_test.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "y_test.to_csv('data/y_test.csv', index=False)\n",
    "\n",
    "import json\n",
    "with open('data/feature_cols.json', 'w') as f:\n",
    "    json.dump(feature_cols, f)\n",
    "\n",
    "print(\"Saved to data/\")\n",
    "print(\"  - processed_data.csv\")\n",
    "print(\"  - X_train.csv, X_test.csv\")\n",
    "print(\"  - y_train.csv, y_test.csv\")\n",
    "print(\"  - feature_cols.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Predictive Maintenance)",
   "language": "python",
   "name": "pm-env"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
